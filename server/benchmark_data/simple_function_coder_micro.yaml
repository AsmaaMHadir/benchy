benchmark_name: "Simple Function Coder"
purpose: "Evaluate the ability of a language model to generate and execute a function."
base_prompt: |
  <purpose>
      Generate a function for a given function-request. Then call the function with the provided arguments. Then print the result.
  </purpose>
  
  <instructions>
      <instruction>Generate only the function requested by the user.</instruction>
      <instruction>Fill in the function body with the appropriate code.</instruction>
      <instruction>Do not include any other text.</instruction>
      <instruction>Write code in python 3.</instruction>
      <instruction>Generate the function, function call, and print the result.</instruction>
      <instruction>Code should be clean and readable.</instruction>
      <instruction>Your code be immediately executed as is. Make sure it's runnable.</instruction>
  </instructions>
  
  <function-request>
      {{function}}
  </function-request>

  <function-arguments>
      {{arguments}}
  </function-arguments>
evaluator: "execute_python_code_with_string_output"
models: ["llama3.2:1b", "qwen2.5-coder:14b"]
model_provider: "ollama"
prompts:
  - dynamic_variables:
      function: "def add(a, b): int - add two numbers"
      arguments: "1, 2"
    expectation: "3"
  - dynamic_variables:
      function: "def multiply_list(numbers: list) -> int - multiply all numbers in a list together"
      arguments: "[2, 3, 4]"
    expectation: "24"
  - dynamic_variables:
      function: "def reverse_string(text: str) -> str - reverse the characters in a string"
      arguments: "'hello world'"
    expectation: "dlrow olleh"
  